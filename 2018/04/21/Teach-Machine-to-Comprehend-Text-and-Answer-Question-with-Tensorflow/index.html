<!DOCTYPE html><html lang="en"><style>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,header,main{display:block}a{background-color:transparent}h1{font-size:2em;margin:.67em 0}img{border:0}body,html{width:100%;height:100%}html{width:100%;height:100vh;display:flex;flex-direction:column;justify-content:center;align-items:center;background:var(--bgColor);--bgColor:#fff;--textColor:#2c3e50;--bg2ndColor:none;--bg3rdColor:#f8f8f8;--preCodeColor:#525252;--imgOpacity:1.0}@media (prefers-color-scheme:dark){html{background:var(--bgColor);--bgColor:#121212;--textColor:#fff;--bg2ndColor:#fff;--bg3rdColor:#332940;--preCodeColor:#f8f8f8;--imgOpacity:0.5}}body{margin:0;color:var(--textColor);font-size:18px;line-height:1.6;background-color:var(--bgColor);font-family:sourcesanspro,'Helvetica Neue',Arial,sans-serif}ul.nav{margin:0;padding:0;list-style-type:none}ul{margin:1rem 0}a{color:var(--textColor);text-decoration:none}.flag-icon{height:25px;width:25px;display:inline;border-radius:50%;vertical-align:sub}.icon_item{padding-left:5px!important;padding-right:5px!important}.reading-progress-bar{background:#42b983;display:block;height:2px;left:0;position:fixed;top:0;width:0;z-index:10001}header{min-height:60px}header .logo-link{float:left}header .nav{float:right;left:80px}header .logo-link img{height:60px}header .nav-list-item{display:inline-block;padding:19px 10px}header .nav-list-item a{line-height:1.4}@media screen and (max-width:900px){header .nav-list-item a{font-size:12px}}@media screen and (min-width:900px){header .nav-list-item a{font-size:18px}}.post{padding-top:1em}.post-block .post-title{margin:.65em 0;color:var(--textColor);font-size:1.5em}.post-block .post-info{color:#7f8c8d}.post-block .post-info .read-time{text-align:right}.post-content h2,.post-content h4{position:relative;margin:1em 0}.post-content h2 :before,.post-content h4 :before{content:"#";color:#42b983;position:absolute;left:-.7em;top:-4px;font-size:1.2em;font-weight:700}.post-content h4 :before{content:">"}.post-content h2{font-size:22px}.post-content h4{font-size:18px}.post-content a{color:#42b983;word-break:break-all}main.container{margin:2em 10px}@media screen and (min-width:900px){.wrap{width:900px;margin:0 auto}header{padding:20px 60px}}@media screen and (max-width:900px){.wrap{width:100%}header{min-height:50px;padding:2px 2px;position:fixed;z-index:10000;border-radius:15px;left:50%;-webkit-transform:translateX(-50%);transform:translateX(-50%);width:-webkit-fit-content;width:-moz-fit-content;width:fit-content}header a.logo-link,header ul.nav.nav-list{float:none;display:inline;text-align:center}header li.nav-list-item{padding:10px 5px}header .logo-link img{height:20px;vertical-align:sub}header .flag-icon{height:20px;width:20px}header{background-color:rgba(255,255,255,.9)}@supports ((-webkit-backdrop-filter:blur(2em)) or (backdrop-filter:blur(2em))){header{background-color:rgba(255,255,255,.3);-webkit-backdrop-filter:blur(10px);backdrop-filter:blur(10px)}}main.container{padding-top:2em}main.container{margin:0 20px}.post-content h2,.post-content h4{max-width:300px;left:15px}}@font-face{font-family:sourcesanspro;src:url(/font/sourcesanspro.woff2) format("woff2"),url(/font/sourcesanspro.woff) format("woff");font-weight:400;font-style:normal}</style><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Teach Machine to Comprehend Text and Answer Question with Tensorflow - Part I · Han Xiao Tech Blog - Neural Search & AI Engineering</title><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@hxiao"><meta name="twitter:creator" content="@hxiao"><meta name="description" content="Reading comprehension is one of the fundamental skills for human, which one must learn systematically since the elementary school. Do you still reme ... · Han Xiao"><meta property="og:title" content="Teach Machine to Comprehend Text and Answer Question with Tensorflow - Part I · Han Xiao Tech Blog - Neural Search &amp; AI Engineering"><meta property="og:description" content="Reading comprehension is one of the fundamental skills for human, which one must learn systematically since the elementary school. Do you still reme ... · Han Xiao"><meta property="og:url" content="https://hanxiao.io/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/"><meta property="og:image" content="https://hanxiao.io/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow//e0e0ba2b.png"><meta property="og:type" content="article"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/myavatar.png"><link rel="alternate" type="application/rss+xml" title="Han Xiao Tech Blog - Neural Search &amp; AI Engineering" href="https://hanxiao.io/atom.xml"><!-- - use css preload trick--><link rel="preload" href="/css/apollo.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="/css/apollo.css"></noscript><script>/*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/
(function( w ){
    "use strict";
    // rel=preload support test
    if( !w.loadCSS ){
        w.loadCSS = function(){};
    }
    // define on the loadCSS obj
    var rp = loadCSS.relpreload = {};
    // rel=preload feature support test
    // runs once and returns a function for compat purposes
    rp.support = (function(){
        var ret;
        try {
            ret = w.document.createElement( "link" ).relList.supports( "preload" );
        } catch (e) {
            ret = false;
        }
        return function(){
            return ret;
        };
    })();

    // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
    // then change that media back to its intended value on load
    rp.bindMediaToggle = function( link ){
        // remember existing media attr for ultimate state, or default to 'all'
        var finalMedia = link.media || "all";

        function enableStylesheet(){
            link.media = finalMedia;
        }

        // bind load handlers to enable media
        if( link.addEventListener ){
            link.addEventListener( "load", enableStylesheet );
        } else if( link.attachEvent ){
            link.attachEvent( "onload", enableStylesheet );
        }

        // Set rel and non-applicable media type to start an async request
        // note: timeout allows this to happen async to let rendering continue in IE
        setTimeout(function(){
            link.rel = "stylesheet";
            link.media = "only x";
        });
        // also enable media after 3 seconds,
        // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
        setTimeout( enableStylesheet, 3000 );
    };

    // loop through link elements in DOM
    rp.poly = function(){
        // double check this to prevent external calls from running
        if( rp.support() ){
            return;
        }
        var links = w.document.getElementsByTagName( "link" );
        for( var i = 0; i < links.length; i++ ){
            var link = links[ i ];
            // qualify links to those with rel=preload and as=style attrs
            if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
                // prevent rerunning on link
                link.setAttribute( "data-loadcss", true );
                // bind listeners to toggle media back
                rp.bindMediaToggle( link );
            }
        }
    };

    // if unsupported, run the polyfill
    if( !rp.support() ){
        // run once at least
        rp.poly();

        // rerun poly on an interval until onload
        var run = w.setInterval( rp.poly, 500 );
        if( w.addEventListener ){
            w.addEventListener( "load", function(){
                rp.poly();
                w.clearInterval( run );
            } );
        } else if( w.attachEvent ){
            w.attachEvent( "onload", function(){
                rp.poly();
                w.clearInterval( run );
            } );
        }
    }


    // commonjs
    if( typeof exports !== "undefined" ){
        exports.loadCSS = loadCSS;
    }
    else {
        w.loadCSS = loadCSS;
    }
}( typeof global !== "undefined" ? global : this ) );</script><script id="mcjs">!function(c,h,i,m,p){m=c.createElement(h),p=c.getElementsByTagName(h)[0],m.async=1,m.src=i,p.parentNode.insertBefore(m,p)}(document,"script","https://chimpstatic.com/mcjs-connected/js/users/7da58fc9885cb85d4a9f0ad9a/987f901145f1749fd3e800e86.js");</script><link rel="search" type="application/opensearchdescription+xml" href="https://hanxiao.io/atom.xml" title="Han Xiao Tech Blog - Neural Search &amp; AI Engineering"></head><body><div class="reading-progress-bar"></div><div class="wrap"><header><ul class="nav nav-list"><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li><li class="nav-list-item"><a href="https://www.linkedin.com/in/hxiao87" target="_blank" class="nav-list-link">LINKEDIN</a></li><li class="nav-list-item"><a href="https://x.com/hxiao" target="_blank" class="nav-list-link">X</a></li><li class="nav-list-item"><a href="https://github.com/hanxiao" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="https://scholar.google.com/citations?user=jp7swwIAAAAJ" target="_blank" class="nav-list-link">SCHOLAR</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Teach Machine to Comprehend Text and Answer Question with Tensorflow - Part I</h1><div class="post-info">Apr 21, 2018 by &nbsp;&nbsp;&nbsp;<img src="/myavatar.png" alt="logo" width="18px" height="18px" style="vertical-align: sub;">&nbsp;<a href="/about" target="_blank" class="nav-list-link">Han Xiao - <i>ex</i> Engineering Lead @ Tencent AI Lab</a></div><div class="post-info"><div class="read-time">◷&nbsp;&nbsp;&nbsp; 20  min read</div></div><div class="post-content"><h2><span id="background">Background</span></h2><div class="tip"><br>  The <a href="/2018/09/09/Dual-Ask-Answer-Network-for-Machine-Reading-Comprehension/" title="part II of this series">part II of this series</a> is avaliable now, in which I present a unified model for asking <em>and</em> answering!<br></div>

<p>Reading comprehension is one of the fundamental skills for human, which one must learn systematically since the elementary school. Do you still remember how the worksheet of your reading class looks like? It usually consists of an article and few questions about its content. To answer these questions, you need to first gather information by collecting answer-related sentences from the article. Sometimes you can directly copy those original sentences from the article as the final answer. This is a trivial “gut question”, and every student likes it. Unfortunately (for students), quite often you need to summarize, assert, infer, refine those evidences and finally write the answer in your own words. Drawing inferences about the writer’s intention is especially hard. Back in <a id="more"></a>high school, I was often confused by the questions like “why did the poet write a sentence like this?” How could I possibly know the <em>original</em> intention of an ancient poet a thousand years ago? How could my teacher know it for sure?</p>
<img src="/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/721ad465.png">
<p>Now at Tencent AI Lab, I’m leading a team teaching machines to comprehend text and answer questions as we did in schools. Why is it interesting to us? Because I believe <strong>the ability to comprehend text will lead us to a better search</strong>. </p>
<p>Considering your journey with a traditional keyword-based search. You have a question in mind and hope the internet can answer you. As a start, you formulate the question with some keywords and type them into the search box. The search engine returns a set of matched documents. Then, you pick top-ranked documents and quickly scan them through, as the answer to the question often hides somewhere in those documents. Finally, you marry multiple ideas from various texts and draw a conclusion about the answer. Note that in this journey, the search engine only helps you filtering out irrelevant documents, leaving the hard tasks such as reading, comprehending and summarizing to yourself. Though the “highlighting” feature of some search engines allows you to quicker locate related passages (n.b. related to the question not to the potential answer, these are different), you still have to identify them and make inference. In other word, the mighty internet <em>doesn’t</em> actually answer your question, you answer it by yourself! The next picture illustrates this process.</p>
<img src="/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/16ffb5e7.png">
<p>Having a search system with the reading comprehension ability can make the user experience smoother and more efficient, as all time-consuming tasks such as retrieving, inferring and summarizing are left to the computers. For impatient users who don’t have time to read text carefully, such system can be very useful. For machine learning developers, such system is challenging. An algorithm that returns query-relevant documents is far from enough. The algorithm should also have the abilities to follow organization of document, to draw inferences from a passage about its contents, and to answer questions answered in a passage.</p>
<p>In this article, I will describe how to implement a reading comprehension system from scratch using Tensorflow. This article is the first part of the reading comprehension series I planed. This first part serves as a tutorial of machine reading comprehension. I will define the problem, propose a general neuron network structure for this task, and try my best to help you understand this challenge. In the second part (<strong>not published yet</strong>), I will discuss more sophisticated network structures and technical details which are required for building a production-level reading comprehension system.</p>
<h4><span id="table-of-content">Table of Content</span></h4><!-- toc -->
<ul>
<li><a href="#problem-definition">Problem Definition</a></li>
<li><a href="#network-architecture">Network Architecture</a></li>
<li><a href="#embedding-and-encoding-layers">Embedding and Encoding Layers</a></li>
<li><a href="#matching-layer">Matching Layer</a></li>
<li><a href="#fusing-layer">Fusing Layer</a></li>
<li><a href="#decoding-layer-loss-function">Decoding Layer &amp; Loss Function</a></li>
<li><a href="#predicting-the-answer-span">Predicting the Answer Span</a></li>
<li><a href="#moving-forward-to-part-ii">Moving Forward to Part II</a></li>
</ul>
<!-- tocstop -->
<h2><span id="problem-definition">Problem Definition</span></h2><p>Given a question $q \in \mathcal{Q}$, let’s start by assuming a search engine already provides us a set of relevant passages $P=\{p_1,\ldots,p_M \,|\, p_i \in \mathcal{P}\}$ (e.g. using <a href="/2018/01/10/Build-Cross-Lingual-End-to-End-Product-Search-using-Tensorflow/" title="symbolic matching">symbolic matching</a>). Each passage $p_i$ consists of few sentences, as illustrated in the “Absolute Location” worksheet above. Note that the answer to $q$ may not be a complete passage or a sentence. It can be a subsequence of a sentence, or a sequence spans over multiple sentences or passages. Without lose of generality, we define two finite integers $s, e\in [0, L)$ to represent the start and end position of the answer, respectively. Here $L$ denotes the total number of tokens of the given passage set. Of course, a valid answer span also requires $e &gt; s$.</p>
<p>Consequently, our training data can be represented as $\mathcal{T}=\{q_i, P_i, (s, e)_i\}_{i=1}^{N}$. Given $\mathcal{T}$ the problem of reading comprehension becomes: finding a function $f: \mathcal{Q}\times\mathcal{P}\rightarrow\mathbb{Z}^2$ which maps a question and a set of passage from their original space (i.e. $\mathcal{P}$ and $\mathcal{Q}$, respectively) to a two-dimensional integer space. To measure the effectiveness of $f$, we also need a loss function $\ell:\mathbb{Z}^2\times\mathbb{Z}^2\rightarrow\mathbb{R}$ to compare the prediction with the groundtruth $(s, e)_i$. The optimal solution $f^{*}$ is defined as </p>
<p>$$f^{*} := \arg\min_f \sum_{i=1}^N\ell\Bigl(f(q_i, \mathcal{P}_i), (s, e)_i\Bigr).$$</p>
<p>Careful readers may now have plenty of questions in mind:</p>
<ul>
<li>What is the exact form of function $f$?</li>
<li>How to represent question and passage in the vector space?</li>
<li>What is a good loss function?</li>
<li>What if an answer contains multiple non-consecutive sequences?</li>
<li>What if an answer must be synthesized rather than extracted from the context, e.g. the 5th question in our first “Absolute Location” worksheet?</li>
</ul>
<p>It is not surprising that I choose deep neuron network to model $f$, as $f$ needs to be complicated enough to capture the deep semantic correlation between passages and questions. I will unfold the remaining parts of this post to answer the aforementioned questions.</p>
<h2><span id="network-architecture">Network Architecture</span></h2><p>The next picture illustrates an overview of a reading comprehension network. From bottom up there are five layers in this network: embedding layer, encoding layer, matching layer, fusion layer and decoding layer. The input to the network are tokens of a question and the corresponding passages. The output from the network are two integers, representing the start and end positions of the answer. Note that the choice of the model is quite open for all layers. For the sake of clarity, I will keep the model as simple as possible and briefly go through each layer. </p>
<img src="/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/dd022bff.png">
<h2><span id="embedding-and-encoding-layers">Embedding and Encoding Layers</span></h2><p>The embedding and encoding layers take in a sequence of tokens and represent it as a sequence of vectors. Here I implement them using a pretrained embedding matrix and bi-directional GRUs. To load a pretrained embedding into the graph:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">embed_shape = [vocab_size, vocab_embed_dim]</span><br><span class="line">embed_placeholder = tf.placeholder(tf.float32, embed_shape)</span><br><span class="line">word_embed = tf.get_variable(<span class="string">'word_embeddings'</span>, embed_shape, trainable=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">embed_init_op = word_embed.assign(embed_placeholder)</span><br><span class="line"></span><br><span class="line"><span class="comment"># to load precomputed embedding from numpy array `pre_embed` to the graph</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(embed_init_op, feed_dict=&#123;embed_placeholder: pre_embed&#125;)</span><br></pre></td></tr></table></figure>
<p>Note that the embedding matrix is initialized only once and not trained in the entire learning process. If you work with a language with a large vocabulary, the embedding matrix would be so big that almost all parameters of the model come from the embedding matrix. Therefore, fixing the embedding can often improve the effectiveness of training.</p>
<p>Encoding question and passage sequence with bidirectional GRU is straightforward using Tensorflow API.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">q_emb = tf.nn.embedding_lookup(word_embed, q)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">'Question_Encoder'</span>):</span><br><span class="line">    cell_fw = GRUCell(num_units=hidden_size)</span><br><span class="line">    cell_bw = GRUCell(num_units=hidden_size)</span><br><span class="line">    output, _ = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, q_emb, sequence_length=q_len)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># concat the forward and backward encoded information</span></span><br><span class="line">    q_encodes = tf.concat(output, <span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># do the same to get `p_encodes`</span></span><br></pre></td></tr></table></figure></p>
<p>The choice of the cell is quite open. For example, <code>GRUCell</code> can be wrapped with <code>DropoutWrapper</code> and <code>MultiRNNCell</code> to get stabler and richer representations. Alternatively, one can share the parameters of the passage encoder and the question encoder to reduce the model size. However, this comes with a cost of less effective training.</p>
<h2><span id="matching-layer">Matching Layer</span></h2><p>Now that we have represented questions and passages into vectors, we need a way to exploit their correlation. Intuitively, not all words are equally useful for answering the question. Therefore, the sequence of passage vectors need to be weighted according to their relations to the question. The next picture illustrates this idea.</p>
<img src="/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/e0e0ba2b.png">
<p><a href="https://www.quora.com/What-is-Attention-Mechanism-in-Neural-Networks" target="_blank" rel="noopener">Attention mechanism</a> is one of the most popular methods to solve this problem. Here I want to introduce an interesting method used in the paper <a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">“Bi-Directional Attention Flow for Machine Comprehension”</a>. The idea is to compute attentions in two directions: from passage to question as well as from question to passage. Both of these attentions are derived from a shared similarity matrix $\mathbf{S}$, in which each element $s_{ij}$ represents the similarity between the $i$th token of the passage and the $j$th token of the question. If we denote the similarity function as $k: \mathbb{R}^D\times\mathbb{R}^D\rightarrow\mathbb{R}$, then each element in  $\mathbf{S}$ can be represented as:</p>
<p>$$s_{ij}=k(\mathbf{p}_{:i}, \mathbf{q}_{:j}).$$</p>
<p>If you come from the pre-deep learning era, then you should be very familiar with the above equation. This old friend is exactly the kernel function used in support vector machines and Gaussian process! Thus, I can also employ RBF kernel, polynomial kernel here for the same purpose. The code below shows a very simple version with a fixed linear kernel. Curious readers are recommended to read <a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">Section 2.4 “Attention Flow Layer” of this paper</a> for more sophisticated “kernel” functions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">p_mask = tf.sequence_mask(p_len, tf.shape(p)[<span class="number">1</span>], dtype=tf.float32, name=<span class="string">'passage_mask'</span>)</span><br><span class="line">q_mask = tf.sequence_mask(q_len, tf.shape(q)[<span class="number">1</span>], dtype=tf.float32, name=<span class="string">'question_mask'</span>)</span><br><span class="line"></span><br><span class="line">sim_matrix = tf.matmul(p_encodes, q_encodes, transpose_b=<span class="literal">True</span>)</span><br><span class="line">sim_mask = tf.matmul(tf.expand_dims(p_mask, <span class="number">-1</span>), tf.expand_dims(q_mask, <span class="number">-1</span>), transpose_b=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mask out zeros by replacing it with very small number</span></span><br><span class="line">sim_matrix -= (<span class="number">1</span> - sim_mask) * <span class="number">1e30</span></span><br><span class="line"></span><br><span class="line">passage2question_attn = tf.matmul(tf.nn.softmax(sim_matrix, <span class="number">-1</span>), q_encodes)</span><br><span class="line"></span><br><span class="line">b = tf.nn.softmax(tf.expand_dims(tf.reduce_max(sim_matrix, <span class="number">2</span>), <span class="number">1</span>), <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">question2passage_attn = tf.tile(tf.matmul(b, p_encodes),</span><br><span class="line">                                [<span class="number">1</span>, tf.shape(p_encodes)[<span class="number">1</span>], <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">p_mask = tf.expand_dims(p_mask, <span class="number">-1</span>)</span><br><span class="line">passage2question_attn *= p_mask</span><br><span class="line">question2passage_attn *= p_mask</span><br><span class="line"></span><br><span class="line">match_out = tf.concat([p_encodes,</span><br><span class="line">                    p_encodes * passage2question_attn,</span><br><span class="line">                    p_encodes * question2passage_attn], <span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<p>Three remarks about this implementation. First, as the length of questions/passages is vary inside each batch, one has to mask out the padded tokens from the calculation to get correct gradient. Since I’m using <code>softmax</code> to normalize the similarity score, the correct way to mask out padded element is to subtract a negative number with large magnitude <em>before</em> doing <code>softmax</code>. </p>
<p>Second, <code>match_out</code> at the last step consists of the original passage encoding and two weighted passage encodings. Concatenating the output from the previous encoding layer can often reduce the information loss caused by the early summarization. </p>
<p>Finally, note that the first two dimensions of <code>match_out</code> is the same as the <code>p_encodes</code> from the encoding layer. They only differ in the last dimension, i.e. depth. As a consequence, one may consider <code>match_out</code> as a passage encoding <em>conditioned on</em> the given question, whereas <code>p_encodes</code> captures the interaction among passage tokens <em>independent of</em> the question. </p>
<h2><span id="fusing-layer">Fusing Layer</span></h2><p>The fusing layer is designed with two purposes. First, capturing the long-term dependencies of <code>match_out</code>. Second, collecting all the evidences so far and preparing for the final decoding. A simple solution would be feeding <code>match_out</code> to a bi-directional RNN. The output of this RNN is then the output of the fusing layer. This implementation looks very similar to our encoding layer described above. Unfortunately, such method is not very efficient in practice, as RNN is generally difficult to parallelize for GPU. Alternatively, I use CNN here to capture long-term dependencies and summarize high-level information. Specifically, I employ (multiple) <code>conv1d</code> layer(s) to cross-correlated with <code>match_out</code> to produce the the output of the fusing layer. The next figure illustrates this idea.</p>
<img src="/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/0071ff68.png">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">out_dim = <span class="number">64</span></span><br><span class="line">window_len = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">conv_match = tf.layers.conv1d(match_out, out_dim, window_len, strides=window_len)</span><br><span class="line">conv_match_up = tf.squeeze(tf.image.resize_images(tf.expand_dims(conv_match, axis=<span class="number">-1</span>), </span><br><span class="line">                                                [tf.shape(match_out)[<span class="number">1</span>], out_dim],</span><br><span class="line">                                                method=ResizeMethod.NEAREST_NEIGHBOR), axis=<span class="number">-1</span>)</span><br><span class="line">fuse_out = tf.concat([p_encodes, match_out, conv_match_up], axis=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<p>The upsampling step is required for concatenating the convoluted features with <code>match_out</code> and <code>p_encodes</code>. It can be implemented with <code>resize_images</code> from Tensorflow API. The size of <code>fuse_out</code> is <code>[B,L,D]</code>, where <code>B</code> is the batch size; <code>L</code> is the passage length and <code>D</code> is the depth controlled by the convolution filters in the fusing layer. </p>
<h2><span id="decoding-layer-amp-loss-function">Decoding Layer &amp; Loss Function</span></h2><p>Our final step is to decode <code>fuse_out</code> as an answer span. In particular, here I decode the fused tensor into two discrete distributions $\widehat{\mathbf{s}}$, $\widehat{\mathbf{e}}$ over $[0, L)$, which represent the start and end probability on every position of a $L$-length passage, respectively. A simple way to get such distribution is to reduce the last dimension of <code>fuse_out</code> to 1 using a dense layer, and then put a <code>softmax</code> over its output.</p>
<p>Having now two labels $s, e\in[0,L)$ and two predicted distributions $\widehat{\mathbf{s}}$, $\widehat{\mathbf{e}}$ over  $[0, L)$, the training loss can be easily measured using the cross-entropy function. The code below shows how to decode an answer span and compute its loss in Tensorflow.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">start_logit = tf.layers.dense(fuse_out, <span class="number">1</span>)</span><br><span class="line">end_logit = tf.layers.dense(fuse_out, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mask out those padded symbols before softmax</span></span><br><span class="line">start_logit -= (<span class="number">1</span> - p_mask) * <span class="number">1e30</span></span><br><span class="line">end_logit -= (<span class="number">1</span> - p_mask) * <span class="number">1e30</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># compute the loss</span></span><br><span class="line">start_loss = tf.losses.sparse_softmax_cross_entropy(labels=start_label, logit=start_logit)</span><br><span class="line">end_loss = tf.losses.sparse_softmax_cross_entropy(labels=end_label, logit=end_logit)</span><br><span class="line">loss = (start_loss + end_loss) / <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<p>Careful readers may realize that I have transformed the original integer prediction problem to a multi-class classification problem. I’m not cheating. In fact, this is one popular way to design the decoder. However, there are some underlying problems of this approach: </p>
<ul>
<li>The <code>start_logit</code> and <code>end_logit</code> are decoded separately, whereas intuitively one expects that the end position depends on the start position. </li>
<li>The loss function is not position-aware. Say the groundtruth of the start position is <code>5</code>, the penalty of decoding it to <code>100</code> would be the same as decoding it to <code>6</code>, even though <code>6</code> is a much better shot.</li>
</ul>
<p>Let’s keep those questions and curiosity in mind, I will discuss about the solution in the second part of this series.</p>
<h2><span id="predicting-the-answer-span">Predicting the Answer Span</span></h2><p>With the start and end distributions $\widehat{\mathbf{s}}$, $\widehat{\mathbf{e}}$ over $[0, L)$, we can compute the probabilities of <em>all</em> answer spans using the <a href="https://en.wikipedia.org/wiki/Outer_product" target="_blank" rel="noopener">outer product</a> of $\widehat{\mathbf{s}}$ and $\widehat{\mathbf{e}}$. Say your total passage length $L$ is 2000, computing $\widehat{\mathbf{s}}\otimes\widehat{\mathbf{e}}$ gives you a <code>[2000, 2000]</code> matrix, of which each element represents the probability of an answer span. The solution space looks pretty huge at the first glance, fortunately not all solutions from this space are valid when you think about it. In fact, the  number of effective solutions is much smaller than 4 million as we shall see.</p>
<p>The reason is that a valid solution must satisfy the constraint of $s$ and $e$. First, $e$ must be greater than $s$, filtering out the lower part of the solution matrix. Second, the answer length $e-s +1$ is often restricted in practice: a good answer should not concise and not too long; it should also not across over sentences, etc. This suggests that a valid solution must be in the central band of the matrix. The next picture illustrates this idea.</p>
<img src="/2018/04/21/Teach-Machine-to-Comprehend-Text-and-Answer-Question-with-Tensorflow/d8a23d38.png">
<p>The optimal solution corresponds to the maximum element in the orange band, whose row-index is the start position and column-index is the end position. The code below shows how to implement it with Tensorflow.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set the maximum answer length</span></span><br><span class="line">max_answ_len = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">start_prob = tf.nn.softmax(start_logit, axis=<span class="number">1</span>)</span><br><span class="line">end_prob = tf.nn.softmax(end_logit, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># do the outer product</span></span><br><span class="line">outer = tf.matmul(tf.expand_dims(start_prob, axis=<span class="number">2</span>),</span><br><span class="line">                  tf.expand_dims(end_prob, axis=<span class="number">1</span>))</span><br><span class="line">outer = tf.matrix_band_part(outer, <span class="number">0</span>, max_answ_len)</span><br><span class="line"></span><br><span class="line">start_pos = tf.argmax(tf.reduce_max(outer, axis=<span class="number">2</span>), axis=<span class="number">1</span>)</span><br><span class="line">end_pos = tf.argmax(tf.reduce_max(outer, axis=<span class="number">1</span>), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract the answer from the original passages</span></span><br><span class="line">final_answer = passage_tokens[start_pos: (end_pos + <span class="number">1</span>)]</span><br></pre></td></tr></table></figure>
<h2><span id="moving-forward-to-part-ii">Moving Forward to Part II</span></h2><p>Machine Reading Comprehension enables computers to understand human language. It is considered as one of the core abilities of artificial intelligence. A good reading comprehension system is a great value for industry applications such as search engines. In this article, I have introduced machine reading comprehension challenge and described a simple network to tackle this challenge. In the second part of this series, we will go through each layer to examine its limitation and replace it with a more sophisticated network structure. See you soon!</p>
</div></article></div></main><footer><div class="paginator"><a href="/2018/06/24/4-Encoding-Blocks-You-Need-to-Know-Besides-LSTM-RNN-in-Tensorflow/" class="prev">&nbsp;❮&nbsp;&nbsp;4 Sequence Encoding ...</a><a href="/2018/01/10/Build-Cross-Lingual-End-to-End-Product-Search-using-Tensorflow/" class="next">Building Cross-Lingu...&nbsp;&nbsp;❯&nbsp;</a></div><div class="footer-section"><h2><img src="/flower.png" alt="Checkout this">Check out these posts too!</h2><div class="archive-readmore"><div style="display: flex; gap: 10px; align-items: flex-start;" class="post-item"><a href="/2019/11/22/Video-Semantic-Search-in-Large-Scale-using-GNES-and-TF-2-0/"><img src="https://hanxiao.io/2019/11/22/Video-Semantic-Search-in-Large-Scale-using-GNES-and-TF-2-0//9ba076d0.png" alt="Video Semantic Search in Large Scale using GNES and Tensorflow 2.0" style="width: 120px; height: 90px; object-fit: cover;"></a><div style="flex: 1;" class="book-title"><h5 style="display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; overflow: hidden; margin: 0;" class="post-title"><a href="/2019/11/22/Video-Semantic-Search-in-Large-Scale-using-GNES-and-TF-2-0/" class="post-title-link">Video Semantic Search in Large Scale using GNES and Tensorflow 2.0</a></h5></div></div><div style="display: flex; gap: 10px; align-items: flex-start;" class="post-item"><a href="/2019/11/07/A-Better-Practice-for-Managing-extras-require-Dependencies-in-Python/"><img src="https://hanxiao.io/2019/11/07/A-Better-Practice-for-Managing-extras-require-Dependencies-in-Python//banner.png" alt="A Better Practice for Managing Many &lt;code&gt;extras_require&lt;/code&gt; Dependencies in Python" style="width: 120px; height: 90px; object-fit: cover;"></a><div style="flex: 1;" class="book-title"><h5 style="display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; overflow: hidden; margin: 0;" class="post-title"><a href="/2019/11/07/A-Better-Practice-for-Managing-extras-require-Dependencies-in-Python/" class="post-title-link">A Better Practice for Managing Many <code>extras_require</code> Dependencies in Python</a></h5></div></div><div style="display: flex; gap: 10px; align-items: flex-start;" class="post-item"><a href="/2019/10/18/GNES-Flow-a-Pythonic-Way-to-Build-Cloud-Native-Neural-Search-Pipelines/"><img src="https://hanxiao.io/2019/10/18/GNES-Flow-a-Pythonic-Way-to-Build-Cloud-Native-Neural-Search-Pipelines//gnes-flow-banner.png" alt="GNES Flow: a Pythonic Way to Build Cloud-Native Neural Search Pipelines" style="width: 120px; height: 90px; object-fit: cover;"></a><div style="flex: 1;" class="book-title"><h5 style="display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; overflow: hidden; margin: 0;" class="post-title"><a href="/2019/10/18/GNES-Flow-a-Pythonic-Way-to-Build-Cloud-Native-Neural-Search-Pipelines/" class="post-title-link">GNES Flow: a Pythonic Way to Build Cloud-Native Neural Search Pipelines</a></h5></div></div><div style="display: flex; gap: 10px; align-items: flex-start;" class="post-item"><a href="/2019/07/29/Generic-Neural-Elastic-Search-From-bert-as-service-and-Go-Way-Beyond/"><img src="https://hanxiao.io/2019/07/29/Generic-Neural-Elastic-Search-From-bert-as-service-and-Go-Way-Beyond//gnes-team-1600.JPG" alt="Generic Neural Elastic Search: From &lt;code&gt;bert-as-service&lt;/code&gt; and Go Way Beyond" style="width: 120px; height: 90px; object-fit: cover;"></a><div style="flex: 1;" class="book-title"><h5 style="display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; overflow: hidden; margin: 0;" class="post-title"><a href="/2019/07/29/Generic-Neural-Elastic-Search-From-bert-as-service-and-Go-Way-Beyond/" class="post-title-link">Generic Neural Elastic Search: From <code>bert-as-service</code> and Go Way Beyond</a></h5></div></div></div></div><div class="copyright"><p>© 2017 - 2025 <a href="https://hanxiao.io">Han Xiao</a>. <img src="/by-nc-sa.svg" alt="Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License." class="image"></p></div></footer></div><link rel="stylesheet" href="/css/post/katex.min.css"><!--link(rel="stylesheet", href=url_for("css/post/gitment.css"))--><script src="/js/katex.min.js"></script><script src="/js/auto-render.min.js"></script><script>renderMathInElement(
    document.body,
    {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "\\[", right: "\\]", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false}
        ]
    }
);</script><!--script(src=url_for("js/gitment.browser.js"))--><!--script(src=url_for("js/gitment.loader.js"))--><script src="/js/jquery-3.4.1.min.js"></script><script src="/js/reading_progress.min.js"></script><script src="/js/highlighter.min.js"></script><script src="/js/init-highlighter.js"></script><script async src="https://www.google-analytics.com/analytics.js"></script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create',"UA-52114253-1",'auto');ga('send','pageview');</script></body></html>